{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7688c9b1-f966-40a4-bc88-6311ebee0ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  6 22:31:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   45C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   36C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_Mar__8_18:18:20_PST_2022\n",
      "Cuda compilation tools, release 11.6, V11.6.124\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\n",
      "GPU 0: Tesla T4 (UUID: GPU-0c3e109d-1905-4f3c-7e40-524f03ccdb69)\n",
      "GPU 1: Tesla T4 (UUID: GPU-f7f45b33-07e3-8ae4-6562-11574575036e)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi \n",
    "!nvcc --version\n",
    "!nvidia-smi -L\n",
    "# to check the gpu allocated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85510d9-e29f-4fde-8769-86414762e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "#for selecting a particular GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ded514-b4c6-46b9-aff5-a170ee70b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format-/datasets/voc_generate_seed.py:27: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fileids = np.loadtxt(f, dtype=np.str).tolist()\n"
     ]
    }
   ],
   "source": [
    "#upload the japanese knotweed dataset first and then run seed to genertate different support sets of 1,3,5,10 \n",
    "!python3 /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/datasets/voc_generate_seed.py\n",
    "#seed generate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f2c2d9-c6ab-47b1-b11e-1305d9ab67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove seed if not needed\n",
    "!rm -rf /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/datasets/vocsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c99deec-48f0-4e1f-8403-1e9a6bfb9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n"
     ]
    }
   ],
   "source": [
    "#download the pre-trained checkpoints\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1TsCUtcTjFwclefyRoPJSRJTOJjJ2SlZM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1TsCUtcTjFwclefyRoPJSRJTOJjJ2SlZM\" -O defrcn_det_r101_base1 && rm -rf /tmp/cookies.txt\n",
    "#create a checkpoint folder and copy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe125186-f237-4860-a7d4-777d9f1ad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the pre-trained wieghts\n",
    "!unzip --qq /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrained -d ImageNetPretrainedExtracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "358e362d-cc65-4aff-8e15-b32f58d84e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save changed ckpt to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth\n",
      "\u001b[32m[02/06 22:28:50 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/06 22:28:50 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml', dist_url='tcp://127.0.0.1:50152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth', 'OUTPUT_DIR', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0', 'TEST.PCB_MODELPATH', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth'], resume=False, start_iter=-1)\n",
      "\u001b[32m[02/06 22:28:50 detectron2]: \u001b[0mContents of args.config_file=configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml:\n",
      "_BASE_: \"../Base-RCNN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"/Path/to/Base/Pretrain/Weight\"\n",
      "  MASK_ON: False\n",
      "  BACKBONE:\n",
      "    FREEZE: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "  RPN:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.0\n",
      "    FREEZE: False\n",
      "  ROI_HEADS:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.001\n",
      "    NUM_CLASSES: 5\n",
      "    FREEZE_FEAT: True\n",
      "    CLS_DROPOUT: True\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TEST: 800\n",
      "DATASETS:\n",
      "  TRAIN: (\"voc_2007_trainval_novel1_1shot_seed0\", )\n",
      "  TEST: (\"voc_2007_test_novel1\",)\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2\n",
      "  BASE_LR: 0.01\n",
      "  STEPS: (640, )\n",
      "  MAX_ITER: 100\n",
      "  CHECKPOINT_PERIOD: 100000\n",
      "  WARMUP_ITERS: 0\n",
      "TEST:\n",
      "  PCB_ENABLE: True\n",
      "  PCB_MODELPATH: \"/Path/to/ImageNet/Pre-Train/Weight\"\n",
      "OUTPUT_DIR: \"/Path/to/Output/Dir\"\n",
      "\u001b[32m[02/06 22:28:50 detectron2]: \u001b[0mFull config saved to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/config.yaml\n",
      "\u001b[32m[02/06 22:28:50 d2.utils.env]: \u001b[0mUsing a generated random seed 50970934\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/06 22:28:51 d2.modeling.backbone.resnet]: \u001b[0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.\n",
      "froze roi_box_head parameters\n",
      "\u001b[32m[02/06 22:28:54 defrcn.dataloader.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[02/06 22:28:54 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 1            |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/06 22:28:54 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/06 22:28:54 defrcn.dataloader.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/06 22:28:54 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 22:28:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "2023-02-06 22:28:54.730179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 22:28:54.861989: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-06 22:28:55.422665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 22:28:55.422748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 22:28:55.422757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[32m[02/06 22:28:56 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth ...\n",
      "\u001b[32m[02/06 22:28:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1\n",
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n",
      "\u001b[32m[02/06 22:29:07 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 19  total_loss: 0.6999  loss_cls: 0.4579  loss_box_reg: 0.1182  loss_rpn_cls: 0.04427  loss_rpn_loc: 0.04209  time: 0.5147  data_time: 0.0166  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/06 22:29:16 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 39  total_loss: 0.2415  loss_cls: 0.1037  loss_box_reg: 0.08178  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.0351  time: 0.5033  data_time: 0.0060  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/06 22:29:27 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 59  total_loss: 0.1988  loss_cls: 0.06767  loss_box_reg: 0.08327  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.02495  time: 0.5084  data_time: 0.0050  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/06 22:29:37 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 79  total_loss: 0.1689  loss_cls: 0.0568  loss_box_reg: 0.07815  loss_rpn_cls: 0.009046  loss_rpn_loc: 0.02102  time: 0.5104  data_time: 0.0054  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/06 22:29:47 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/model_final.pth\n",
      "\u001b[32m[02/06 22:29:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.1439  loss_cls: 0.05094  loss_box_reg: 0.06286  loss_rpn_cls: 0.005967  loss_rpn_loc: 0.01994  time: 0.5104  data_time: 0.0058  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/06 22:29:49 d2.engine.hooks]: \u001b[0mOverall training speed: 97 iterations in 0:00:49 (0.5104 s / it)\n",
      "\u001b[32m[02/06 22:29:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:50 (0:00:01 on hooks)\n",
      "\u001b[32m[02/06 22:29:49 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 23           |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/06 22:29:49 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 22:29:49 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 22:29:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/06 22:29:49 defrcn.evaluation.evaluator]: \u001b[0mStart initializing PCB module, please wait a seconds...\n",
      "\u001b[32m[02/06 22:29:49 defrcn.evaluation.calibration_layer]: \u001b[0mLoading ImageNet Pre-train Model from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth\n",
      "\u001b[32m[02/06 22:29:50 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 22:29:50 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 22:29:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/06 22:29:50 defrcn.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[02/06 22:29:57 defrcn.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03 (0.600000 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/06 22:29:57 defrcn.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.644832 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/06 22:29:57 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_2007_test_novel1 using 2007 metric. Note that results do not use the official Matlab API.\n",
      "\u001b[32m[02/06 22:29:58 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate per-class mAP50:\n",
      "|  Japanese Knotweed  |\n",
      "|:-------------------:|\n",
      "|        0.216        |\n",
      "\u001b[32m[02/06 22:29:58 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate overall bbox:\n",
      "|  AP   |  AP50  |  AP75  |  nAP  |  nAP50  |  nAP75  |\n",
      "|:-----:|:------:|:------:|:-----:|:-------:|:-------:|\n",
      "| 0.032 | 0.216  | 0.000  | 0.032 |  0.216  |  0.000  |\n",
      "\u001b[32m[02/06 22:29:58 defrcn.engine.defaults]: \u001b[0mEvaluation results for voc_2007_test_novel1 in csv format:\n",
      "\u001b[32m[02/06 22:29:58 defrcn.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[02/06 22:29:58 defrcn.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,nAP,nAP50,nAP75\n",
      "\u001b[32m[02/06 22:29:58 defrcn.evaluation.testing]: \u001b[0mcopypaste: 0.0325,0.2165,0.0000,0.0325,0.2165,0.0000\n",
      "Reformat all results -> /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/results.txt\n"
     ]
    }
   ],
   "source": [
    "!bash run_voc.sh runDeFrcn 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8750caa-c08d-413a-b521-e6ab9cea42f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
