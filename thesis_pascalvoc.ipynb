{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7688c9b1-f966-40a4-bc88-6311ebee0ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 11 23:59:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   39C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   40C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_Mar__8_18:18:20_PST_2022\n",
      "Cuda compilation tools, release 11.6, V11.6.124\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\n",
      "GPU 0: Tesla T4 (UUID: GPU-b6882596-52ee-4df9-26e4-28e7ce0a571f)\n",
      "GPU 1: Tesla T4 (UUID: GPU-392f238b-39d9-343e-5318-5368661860a4)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi \n",
    "!nvcc --version\n",
    "!nvidia-smi -L\n",
    "# to check the gpu allocated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85510d9-e29f-4fde-8769-86414762e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "#for selecting a particular GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ded514-b4c6-46b9-aff5-a170ee70b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format-/datasets/voc_generate_seed.py:27: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fileids = np.loadtxt(f, dtype=np.str).tolist()\n"
     ]
    }
   ],
   "source": [
    "#upload the japanese knotweed dataset first and then run seed to genertate different support sets of 1,3,5,10 \n",
    "!python3 /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/datasets/voc_generate_seed.py\n",
    "#seed generate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f2c2d9-c6ab-47b1-b11e-1305d9ab67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove seed if not needed\n",
    "!rm -rf /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/datasets/vocsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c99deec-48f0-4e1f-8403-1e9a6bfb9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n"
     ]
    }
   ],
   "source": [
    "#download the pre-trained checkpoints\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1TsCUtcTjFwclefyRoPJSRJTOJjJ2SlZM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1TsCUtcTjFwclefyRoPJSRJTOJjJ2SlZM\" -O defrcn_det_r101_base1 && rm -rf /tmp/cookies.txt\n",
    "#create a checkpoint folder and copy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe125186-f237-4860-a7d4-777d9f1ad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the pre-trained wieghts\n",
    "!unzip --qq /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrained -d ImageNetPretrainedExtracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b92b8807-46a6-4d0d-b50c-256102e4e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save changed ckpt to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth\n",
      "\u001b[32m[02/11 17:43:31 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/11 17:43:31 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml', dist_url='tcp://127.0.0.1:50152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth', 'OUTPUT_DIR', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0', 'TEST.PCB_MODELPATH', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth'], resume=False, start_iter=-1)\n",
      "\u001b[32m[02/11 17:43:31 detectron2]: \u001b[0mContents of args.config_file=configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml:\n",
      "_BASE_: \"../Base-RCNN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"/Path/to/Base/Pretrain/Weight\"\n",
      "  MASK_ON: False\n",
      "  BACKBONE:\n",
      "    FREEZE: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "  RPN:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.0\n",
      "    FREEZE: False\n",
      "  ROI_HEADS:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.001\n",
      "    NUM_CLASSES: 5\n",
      "    FREEZE_FEAT: True\n",
      "    CLS_DROPOUT: True\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TEST: 800\n",
      "DATASETS:\n",
      "  TRAIN: (\"voc_2007_trainval_novel1_1shot_seed0\", )\n",
      "  TEST: (\"voc_2007_test_novel1\",)\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2\n",
      "  BASE_LR: 0.01\n",
      "  STEPS: (640, )\n",
      "  MAX_ITER: 100\n",
      "  CHECKPOINT_PERIOD: 100000\n",
      "  WARMUP_ITERS: 0\n",
      "TEST:\n",
      "  PCB_ENABLE: True\n",
      "  PCB_MODELPATH: \"/Path/to/ImageNet/Pre-Train/Weight\"\n",
      "OUTPUT_DIR: \"/Path/to/Output/Dir\"\n",
      "\u001b[32m[02/11 17:43:31 detectron2]: \u001b[0mFull config saved to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/config.yaml\n",
      "\u001b[32m[02/11 17:43:31 d2.utils.env]: \u001b[0mUsing a generated random seed 31984475\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/11 17:43:32 d2.modeling.backbone.resnet]: \u001b[0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.\n",
      "froze roi_box_head parameters\n",
      "\u001b[32m[02/11 17:43:35 defrcn.dataloader.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[02/11 17:43:35 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 1            |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 17:43:35 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/11 17:43:35 defrcn.dataloader.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/11 17:43:35 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:43:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "2023-02-11 17:43:35.534605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 17:43:35.668863: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-11 17:43:36.241474: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 17:43:36.241543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 17:43:36.241549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[32m[02/11 17:43:37 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth ...\n",
      "\u001b[32m[02/11 17:43:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1\n",
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n",
      "\u001b[32m[02/11 17:43:47 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 19  total_loss: 0.7408  loss_cls: 0.3627  loss_box_reg: 0.1109  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.0613  time: 0.5468  data_time: 0.0210  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:43:58 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 39  total_loss: 0.3049  loss_cls: 0.1112  loss_box_reg: 0.1058  loss_rpn_cls: 0.03179  loss_rpn_loc: 0.02848  time: 0.5282  data_time: 0.0062  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:44:08 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 59  total_loss: 0.1901  loss_cls: 0.07218  loss_box_reg: 0.07529  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.01917  time: 0.5218  data_time: 0.0058  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:44:18 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 79  total_loss: 0.2109  loss_cls: 0.0671  loss_box_reg: 0.08132  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.03193  time: 0.5226  data_time: 0.0064  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:44:29 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/model_final.pth\n",
      "\u001b[32m[02/11 17:44:31 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.1845  loss_cls: 0.05517  loss_box_reg: 0.06015  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.02693  time: 0.5231  data_time: 0.0059  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:44:31 d2.engine.hooks]: \u001b[0mOverall training speed: 97 iterations in 0:00:50 (0.5231 s / it)\n",
      "\u001b[32m[02/11 17:44:31 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:52 (0:00:01 on hooks)\n",
      "\u001b[32m[02/11 17:44:31 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 23           |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 17:44:31 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/11 17:44:31 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:44:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/11 17:44:31 defrcn.evaluation.evaluator]: \u001b[0mStart initializing PCB module, please wait a seconds...\n",
      "\u001b[32m[02/11 17:44:31 defrcn.evaluation.calibration_layer]: \u001b[0mLoading ImageNet Pre-train Model from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth\n",
      "\u001b[32m[02/11 17:44:32 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/11 17:44:32 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:44:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/11 17:44:32 defrcn.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03 (0.600000 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.622835 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_2007_test_novel1 using 2007 metric. Note that results do not use the official Matlab API.\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate per-class mAP50:\n",
      "|  Japanese Knotweed  |\n",
      "|:-------------------:|\n",
      "|        0.826        |\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate overall bbox:\n",
      "|  AP   |  AP50  |  AP75  |  nAP  |  nAP50  |  nAP75  |\n",
      "|:-----:|:------:|:------:|:-----:|:-------:|:-------:|\n",
      "| 0.083 | 0.826  | 0.000  | 0.083 |  0.826  |  0.000  |\n",
      "\u001b[32m[02/11 17:44:39 defrcn.engine.defaults]: \u001b[0mEvaluation results for voc_2007_test_novel1 in csv format:\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,nAP,nAP50,nAP75\n",
      "\u001b[32m[02/11 17:44:39 defrcn.evaluation.testing]: \u001b[0mcopypaste: 0.0826,0.8264,0.0000,0.0826,0.8264,0.0000\n",
      "Reformat all results -> /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/results.txt\n"
     ]
    }
   ],
   "source": [
    "!bash run_voc.sh runDeFrcn 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e2eb240-a88c-436e-ad20-c4dacd06bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save changed ckpt to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth\n",
      "\u001b[32m[02/11 17:16:30 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/11 17:16:30 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml', dist_url='tcp://127.0.0.1:50152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth', 'OUTPUT_DIR', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0', 'TEST.PCB_MODELPATH', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth'], resume=False, start_iter=-1)\n",
      "\u001b[32m[02/11 17:16:30 detectron2]: \u001b[0mContents of args.config_file=configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml:\n",
      "_BASE_: \"../Base-RCNN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"/Path/to/Base/Pretrain/Weight\"\n",
      "  MASK_ON: False\n",
      "  BACKBONE:\n",
      "    FREEZE: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "  RPN:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.0\n",
      "    FREEZE: False\n",
      "  ROI_HEADS:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.001\n",
      "    NUM_CLASSES: 5\n",
      "    FREEZE_FEAT: True\n",
      "    CLS_DROPOUT: True\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TEST: 800\n",
      "DATASETS:\n",
      "  TRAIN: (\"voc_2007_trainval_novel1_1shot_seed0\", )\n",
      "  TEST: (\"voc_2007_test_novel1\",)\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2\n",
      "  BASE_LR: 0.01\n",
      "  STEPS: (640, )\n",
      "  MAX_ITER: 100\n",
      "  CHECKPOINT_PERIOD: 100000\n",
      "  WARMUP_ITERS: 0\n",
      "TEST:\n",
      "  PCB_ENABLE: True\n",
      "  PCB_MODELPATH: \"/Path/to/ImageNet/Pre-Train/Weight\"\n",
      "OUTPUT_DIR: \"/Path/to/Output/Dir\"\n",
      "\u001b[32m[02/11 17:16:30 detectron2]: \u001b[0mFull config saved to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/config.yaml\n",
      "\u001b[32m[02/11 17:16:30 d2.utils.env]: \u001b[0mUsing a generated random seed 30500613\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/11 17:16:30 d2.modeling.backbone.resnet]: \u001b[0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.\n",
      "froze roi_box_head parameters\n",
      "\u001b[32m[02/11 17:16:34 defrcn.dataloader.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[02/11 17:16:34 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 1            |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 17:16:34 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/11 17:16:34 defrcn.dataloader.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/11 17:16:34 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:16:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "2023-02-11 17:16:34.089144: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 17:16:34.224023: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-11 17:16:34.798165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 17:16:34.798248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 17:16:34.798259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[32m[02/11 17:16:35 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth ...\n",
      "\u001b[32m[02/11 17:16:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1\n",
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n",
      "\u001b[32m[02/11 17:16:45 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 19  total_loss: 0.7871  loss_cls: 0.3952  loss_box_reg: 0.1265  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.03973  time: 0.5068  data_time: 0.0205  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:16:55 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 39  total_loss: 0.3295  loss_cls: 0.124  loss_box_reg: 0.1222  loss_rpn_cls: 0.02671  loss_rpn_loc: 0.02619  time: 0.5016  data_time: 0.0062  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:17:06 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 59  total_loss: 0.2524  loss_cls: 0.08816  loss_box_reg: 0.09661  loss_rpn_cls: 0.02368  loss_rpn_loc: 0.0332  time: 0.5088  data_time: 0.0057  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:17:16 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 79  total_loss: 0.203  loss_cls: 0.07293  loss_box_reg: 0.08253  loss_rpn_cls: 0.009012  loss_rpn_loc: 0.02793  time: 0.5129  data_time: 0.0063  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:17:27 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/model_final.pth\n",
      "\u001b[32m[02/11 17:17:28 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.1857  loss_cls: 0.06458  loss_box_reg: 0.0832  loss_rpn_cls: 0.008002  loss_rpn_loc: 0.02844  time: 0.5153  data_time: 0.0059  lr: 0.01  max_mem: 2308M\n",
      "\u001b[32m[02/11 17:17:28 d2.engine.hooks]: \u001b[0mOverall training speed: 97 iterations in 0:00:49 (0.5153 s / it)\n",
      "\u001b[32m[02/11 17:17:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:51 (0:00:01 on hooks)\n",
      "\u001b[32m[02/11 17:17:28 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 23           |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 17:17:28 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/11 17:17:28 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:17:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/11 17:17:28 defrcn.evaluation.evaluator]: \u001b[0mStart initializing PCB module, please wait a seconds...\n",
      "\u001b[32m[02/11 17:17:28 defrcn.evaluation.calibration_layer]: \u001b[0mLoading ImageNet Pre-train Model from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth\n",
      "\u001b[32m[02/11 17:17:29 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/11 17:17:29 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 17:17:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/11 17:17:30 defrcn.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03 (0.600000 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.634695 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_2007_test_novel1 using 2007 metric. Note that results do not use the official Matlab API.\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate per-class mAP50:\n",
      "|  Japanese Knotweed  |\n",
      "|:-------------------:|\n",
      "|        0.253        |\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluate overall bbox:\n",
      "|  AP   |  AP50  |  AP75  |  nAP  |  nAP50  |  nAP75  |\n",
      "|:-----:|:------:|:------:|:-----:|:-------:|:-------:|\n",
      "| 0.051 | 0.253  | 0.000  | 0.051 |  0.253  |  0.000  |\n",
      "\u001b[32m[02/11 17:17:37 defrcn.engine.defaults]: \u001b[0mEvaluation results for voc_2007_test_novel1 in csv format:\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,nAP,nAP50,nAP75\n",
      "\u001b[32m[02/11 17:17:37 defrcn.evaluation.testing]: \u001b[0mcopypaste: 0.0505,0.2525,0.0000,0.0505,0.2525,0.0000\n",
      "Reformat all results -> /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/results.txt\n"
     ]
    }
   ],
   "source": [
    "!bash run_voc.sh runDeFrcn 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1106e79c-881a-48f2-b0a7-dc28013adb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/data/visual_train_test.py\", line 1, in <module>\n",
      "    from detectron2.utils.visualizer import Visualizer\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/__init__.py\", line 5, in <module>\n",
      "    setup_environment()\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/utils/env.py\", line 101, in setup_environment\n",
      "    _configure_libraries()\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/utils/env.py\", line 67, in _configure_libraries\n",
      "    if int(cv2.__version__.split(\".\")[0]) >= 3:\n",
      "AttributeError: module 'cv2' has no attribute '__version__'\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/data/visual_train_test.py --source train --config-file /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/config1.yaml --output-dir /home/jovyan/thesis_s2577712/DeFRCN_voc_format --show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc2ef1b0-78a6-433e-ac1d-cd32875e352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/jovyan/.local/lib/python3.8/site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless -y \n",
    "\n",
    "!pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4757fb1d-dc99-4484-851c-09418a476ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv-contrib-python         4.7.0.68\n",
      "opencv-python                 4.7.0.68\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8f818d5-e38a-4c53-a11a-cac43ad681ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save changed ckpt to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth\n",
      "\u001b[32m[02/11 23:50:37 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/11 23:50:37 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml', dist_url='tcp://127.0.0.1:50152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth', 'OUTPUT_DIR', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0', 'TEST.PCB_MODELPATH', '/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth'], resume=False, start_iter=-1)\n",
      "\u001b[32m[02/11 23:50:37 detectron2]: \u001b[0mContents of args.config_file=configs/voc/defrcn_fsod_r101_novel1_1shot_seed0.yaml:\n",
      "_BASE_: \"../Base-RCNN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"/Path/to/Base/Pretrain/Weight\"\n",
      "  MASK_ON: False\n",
      "  BACKBONE:\n",
      "    FREEZE: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "  RPN:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.0\n",
      "    FREEZE: False\n",
      "  ROI_HEADS:\n",
      "    ENABLE_DECOUPLE: True\n",
      "    BACKWARD_SCALE: 0.001\n",
      "    NUM_CLASSES: 1\n",
      "    FREEZE_FEAT: True\n",
      "    CLS_DROPOUT: True\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TEST: 800\n",
      "DATASETS:\n",
      "  TRAIN: (\"voc_2007_trainval_novel1_1shot_seed0\", )\n",
      "  TEST: (\"voc_2007_test_novel1\",)\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2\n",
      "  BASE_LR: 0.01\n",
      "  STEPS: (640, )\n",
      "  MAX_ITER: 100\n",
      "  CHECKPOINT_PERIOD: 100000\n",
      "  WARMUP_ITERS: 0\n",
      "TEST:\n",
      "  PCB_ENABLE: True\n",
      "  PCB_MODELPATH: \"/Path/to/ImageNet/Pre-Train/Weight\"\n",
      "OUTPUT_DIR: \"/Path/to/Output/Dir\"\n",
      "\u001b[32m[02/11 23:50:37 detectron2]: \u001b[0mFull config saved to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/config.yaml\n",
      "\u001b[32m[02/11 23:50:37 d2.utils.env]: \u001b[0mUsing a generated random seed 37352747\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/11 23:50:37 d2.modeling.backbone.resnet]: \u001b[0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.\n",
      "froze roi_box_head parameters\n",
      "Applying reszing-------------------->224x224\n",
      "\u001b[32m[02/11 23:50:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [Resize(shape=(224, 224))]\n",
      "\u001b[32m[02/11 23:50:40 defrcn.dataloader.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[02/11 23:50:40 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 1            |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 23:50:40 defrcn.dataloader.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/11 23:50:40 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 23:50:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "2023-02-11 23:50:41.311181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 23:50:41.463450: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-11 23:50:42.102189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 23:50:42.102260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jovyan/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-11 23:50:42.102269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[32m[02/11 23:50:43 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_det_r101_base1/model_reset_remove.pth ...\n",
      "\u001b[32m[02/11 23:50:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1\n",
      "/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n",
      "\u001b[32m[02/11 23:50:50 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 19  total_loss: 0.2938  loss_cls: 0.2569  loss_box_reg: 0.02171  loss_rpn_cls: 0.003466  loss_rpn_loc: 0.0009942  time: 0.3095  data_time: 0.0332  lr: 0.01  max_mem: 1574M\n",
      "\u001b[32m[02/11 23:50:56 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 39  total_loss: 0.3036  loss_cls: 0.2798  loss_box_reg: 0.02565  loss_rpn_cls: 0.0004161  loss_rpn_loc: 0.0006915  time: 0.3125  data_time: 0.0051  lr: 0.01  max_mem: 1574M\n",
      "\u001b[32m[02/11 23:51:02 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 59  total_loss: 0.08837  loss_cls: 0.07275  loss_box_reg: 0.01725  loss_rpn_cls: 0.000123  loss_rpn_loc: 0.0007062  time: 0.3145  data_time: 0.0054  lr: 0.01  max_mem: 1574M\n",
      "\u001b[32m[02/11 23:51:09 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 79  total_loss: 0.05624  loss_cls: 0.04181  loss_box_reg: 0.01327  loss_rpn_cls: 0.0001096  loss_rpn_loc: 0.0006199  time: 0.3157  data_time: 0.0052  lr: 0.01  max_mem: 1574M\n",
      "\u001b[32m[02/11 23:51:15 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/checkpoints/voc/runDeFrcn/defrcn_fsod_r101_novel1/fsrw-like/1shot_seed0_repeat0/model_final.pth\n",
      "\u001b[32m[02/11 23:51:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.03821  loss_cls: 0.02679  loss_box_reg: 0.01018  loss_rpn_cls: 0.0001045  loss_rpn_loc: 0.0005123  time: 0.3164  data_time: 0.0047  lr: 0.01  max_mem: 1574M\n",
      "\u001b[32m[02/11 23:51:17 d2.engine.hooks]: \u001b[0mOverall training speed: 97 iterations in 0:00:30 (0.3164 s / it)\n",
      "\u001b[32m[02/11 23:51:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:32 (0:00:01 on hooks)\n",
      "Applying reszing-------------------->224x224\n",
      "\u001b[32m[02/11 23:51:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [Resize(shape=(224, 224))]\n",
      "\u001b[32m[02/11 23:51:17 defrcn.dataloader.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category    | #instances   |\n",
      "|:-------------:|:-------------|\n",
      "| Japanese Kn.. | 23           |\n",
      "|               |              |\u001b[0m\n",
      "\u001b[32m[02/11 23:51:17 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 23:51:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[02/11 23:51:17 defrcn.evaluation.evaluator]: \u001b[0mStart initializing PCB module, please wait a seconds...\n",
      "\u001b[32m[02/11 23:51:17 defrcn.evaluation.calibration_layer]: \u001b[0mLoading ImageNet Pre-train Model from /home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/ImageNetPretrainedExtracted/ImageNetPretrained/torchvision/resnet101-5d3b4d8f.pth\n",
      "\u001b[32m[02/11 23:51:18 defrcn.dataloader.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/11 23:51:18 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/11 23:51:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 68, in <module>\n",
      "    launch(\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/engine/launch.py\", line 62, in launch\n",
      "    main_func(*args)\n",
      "  File \"main.py\", line 63, in main\n",
      "    return trainer.train()\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/engine/defaults.py\", line 387, in train\n",
      "    super().train(self.start_iter, self.max_iter)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 144, in train\n",
      "    self.after_train()\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 153, in after_train\n",
      "    h.after_train()\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/engine/hooks.py\", line 80, in after_train\n",
      "    self._do_eval()\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/engine/hooks.py\", line 39, in _do_eval\n",
      "    results = self._func()\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/engine/defaults.py\", line 337, in test_and_save_results\n",
      "    self._last_eval_results = self.test(self.cfg, self.model)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/engine/defaults.py\", line 504, in test\n",
      "    results_i = inference_on_dataset(model, data_loader, evaluator, cfg)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/evaluator.py\", line 90, in inference_on_dataset\n",
      "    pcb = PrototypicalCalibrationBlock(cfg)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/calibration_layer.py\", line 28, in __init__\n",
      "    self.prototypes = self.build_prototypes()\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/calibration_layer.py\", line 58, in build_prototypes\n",
      "    features = self.extract_roi_features(img, boxes)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/calibration_layer.py\", line 98, in extract_roi_features\n",
      "    conv_feature = self.imagenet_model(images.tensor[:, [2, 1, 0]])[1]  # size: BxCxHxW\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/archs/resnet.py\", line 203, in forward\n",
      "    x = self.layer3(x)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jovyan/thesis_s2577712/DeFRCN_voc_format/thesis-pascal_voc_format/defrcn/evaluation/archs/resnet.py\", line 106, in forward\n",
      "    out = self.conv3(out)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 419, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 415, in _conv_forward\n",
      "    return F.conv2d(input, weight, self.bias, self.stride,\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 14.56 GiB total capacity; 13.41 GiB already allocated; 114.44 MiB free; 13.57 GiB reserved in total by PyTorch)\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/extract_results.py\", line 59, in <module>\n",
      "    main()\n",
      "  File \"tools/extract_results.py\", line 34, in main\n",
      "    results.append([fid] + [float(x) for x in res_info.split(':')[-1].split(',')])\n",
      "  File \"tools/extract_results.py\", line 34, in <listcomp>\n",
      "    results.append([fid] + [float(x) for x in res_info.split(':')[-1].split(',')])\n",
      "ValueError: could not convert string to float: ' Serialized dataset takes 0.00 MiB'\n"
     ]
    }
   ],
   "source": [
    "!bash run_voc.sh runDeFrcn 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23fe31d3-7e8c-49ea-aaf0-f80cb33f7927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/jovyan/.local/lib/python3.8/site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless -y \n",
    "\n",
    "!pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41985ddc-3c20-4967-a5bd-60fa9904c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.7.0.68\n",
      "Uninstalling opencv-python-4.7.0.68:\n",
      "  Would remove:\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/cv2/*\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python-4.7.0.68.dist-info/*\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libQt5Core-b6e66ee2.so.5.15.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libQt5Gui-dd62182f.so.5.15.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libQt5Test-c38a5234.so.5.15.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libQt5Widgets-e69d94fb.so.5.15.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libQt5XcbQpa-dcb826d0.so.5.15.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libX11-xcb-69166bdf.so.1.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libXau-00ec42fe.so.6.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libavcodec-087c3416.so.59.37.100\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libavformat-85e01647.so.59.27.100\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libavutil-82c407cb.so.57.28.100\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libcrypto-9cee340d.so.1.1\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libgfortran-91cc3cb1.so.3.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libopenblas-r0-f650aae0.3.3.so\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libpng16-186fce2e.so.16.37.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libquadmath-96973f99.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libssl-16e42f2f.so.1.1\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libswresample-d02fa90a.so.4.7.100\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libswscale-9b504c0d.so.6.7.100\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libvpx-5d0a9e1a.so.7.1.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-icccm-413c9f41.so.4.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-image-e82a276d.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-keysyms-21015570.so.1.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-randr-a96a5a87.so.0.1.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-render-637b984a.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-render-util-43ce00f5.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-shape-25c2b258.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-shm-7a199f70.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-sync-89374f40.so.1.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-util-4d666913.so.1.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-xfixes-9be3ba6f.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-xinerama-ae147f87.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxcb-xkb-9ba31ab3.so.1.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxkbcommon-71ae2972.so.0.0.0\n",
      "    /home/jovyan/.local/lib/python3.8/site-packages/opencv_python.libs/libxkbcommon-x11-c65ed502.so.0.0.0\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless) (1.23.1)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.7.0.68\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92fa0b66-48e8-4394-ae3b-fa2576ef6fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from opencv-contrib-python) (1.23.1)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.7.0.68\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca88ef-4ae6-4e67-b6da-3810d5bdd62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
